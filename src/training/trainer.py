"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
"""
import os
import json
import threading
import time
import tempfile
import traceback
from datetime import datetime
from typing import Tuple
from ..config.settings import DEFAULT_CONFIG, API_CONFIG
from ..utils import log, process_single_instruction

def generate_mbpp_training_data(mbpp_path: str, output_path: str, max_items: int = 50, 
                              start_index: int = 0) -> Tuple[bool, str]:
    """
    ç”ŸæˆMBPPè®­ç»ƒæ•°æ®
    """
    try:
        # å¯¼å…¥requestsï¼ˆå»¶è¿Ÿå¯¼å…¥ä»¥é¿å…ä¾èµ–é—®é¢˜ï¼‰
        try:
            import requests
        except ImportError:
            log("âŒ æœªå®‰è£…requestsåº“ï¼Œæ— æ³•è°ƒç”¨API")
            return False, "è¯·å®‰è£…requestsåº“: pip install requests"
        
        log(f"è¯»å–MBPPæ•°æ®é›†: {mbpp_path}")
        if not os.path.exists(mbpp_path):
            return False, f"MBPPæ•°æ®é›†ä¸å­˜åœ¨: {mbpp_path}"
        
        instructions = []
        with open(mbpp_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and line.startswith('"') and line.endswith('"'):
                    # ç§»é™¤å¼•å·
                    instruction = line[1:-1]
                    instructions.append(instruction)
        
        total_instructions = len(instructions)
        log(f"å…±è¯»å– {total_instructions} æ¡æŒ‡ä»¤")
        
        # é™åˆ¶å¤„ç†æ•°é‡
        if max_items:
            instructions = instructions[:max_items]
            total_instructions = len(instructions)
            log(f"é™åˆ¶å¤„ç†æ•°é‡ä¸º: {total_instructions}")
        
        # è·³è¿‡å·²å¤„ç†çš„
        if start_index > 0:
            instructions = instructions[start_index:]
            log(f"ä»ç´¢å¼• {start_index} å¼€å§‹å¤„ç†")
        
        if not instructions:
            return True, "æ²¡æœ‰éœ€è¦å¤„ç†çš„æŒ‡ä»¤"
        
        log(f"å¼€å§‹å¤„ç† {len(instructions)} æ¡æŒ‡ä»¤...")
        
        # å¤„ç†æ¯æ¡æŒ‡ä»¤
        successful_pairs = []
        
        for i, instruction in enumerate(instructions, start=1):
            try:
                success, code, validation_msg = process_single_instruction(instruction, i)
                
                if success:
                    training_pair = {
                        "instruction": instruction,
                        "code": code,
                        "metadata": {
                            "index": i,
                            "timestamp": datetime.now().isoformat(),
                            "validation_result": validation_msg,
                            "source": "mbpp_dataset_generated"
                        }
                    }
                    successful_pairs.append(training_pair)
                    log(f"[{i}] âœ… æˆåŠŸç”Ÿæˆæ•°æ®å¯¹")
                else:
                    log(f"[{i}] âŒ æ•°æ®å¯¹ç”Ÿæˆå¤±è´¥: {validation_msg}")
                
                # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
                time.sleep(0.5)
                
            except Exception as e:
                log(f"[{i}] âŒ å¤„ç†å¼‚å¸¸: {str(e)}")
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        if successful_pairs:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                for pair in successful_pairs:
                    f.write(json.dumps({
                        "instruction": pair["instruction"],
                        "code": pair["code"]
                    }, ensure_ascii=False) + '\n')
            
            log(f"âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ: {len(successful_pairs)}/{len(instructions)} æ¡æˆåŠŸ")
            log(f"è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            
            return True, f"æˆåŠŸç”Ÿæˆ {len(successful_pairs)} ä¸ªè®­ç»ƒæ•°æ®å¯¹"
        else:
            return False, "æœªç”Ÿæˆä»»ä½•è®­ç»ƒæ•°æ®å¯¹"
            
    except Exception as e:
        return False, f"ç”Ÿæˆè®­ç»ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}"

class TrainingThread(threading.Thread):
    """è®­ç»ƒçº¿ç¨‹"""
    def __init__(self, config, callback=None):
        super().__init__()
        self.config = config
        self.callback = callback
        self.daemon = True
        
    def log(self, message):
        if self.callback:
            self.callback(message)
        log(message)
        
    def run(self):
        try:
            # æ­¥éª¤1: ç”Ÿæˆè®­ç»ƒæ•°æ®
            self.log("=" * 60)
            self.log("ç¬¬ä¸€æ­¥: ç”Ÿæˆè®­ç»ƒæ•°æ®")
            self.log("=" * 60)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆè®­ç»ƒæ•°æ®
            mbpp_path = self.config.get('mbpp_dataset_path', DEFAULT_CONFIG["mbpp_dataset_path"])
            training_data_path = self.config.get('training_dataset_path', DEFAULT_CONFIG["training_dataset_path"])
            max_generate_items = self.config.get('max_generate_items', DEFAULT_CONFIG["max_generate_items"])
            
            # å¦‚æœè®­ç»ƒæ•°æ®ä¸å­˜åœ¨æˆ–éœ€è¦é‡æ–°ç”Ÿæˆ
            if not os.path.exists(training_data_path):
                self.log(f"è®­ç»ƒæ•°æ®ä¸å­˜åœ¨ï¼Œå¼€å§‹ç”Ÿæˆ...")
                self.log(f"MBPPæ•°æ®é›†: {mbpp_path}")
                self.log(f"è¾“å‡ºè·¯å¾„: {training_data_path}")
                self.log(f"æœ€å¤§ç”Ÿæˆæ•°é‡: {max_generate_items}")
                
                success, msg = generate_mbpp_training_data(
                    mbpp_path, 
                    training_data_path,
                    max_items=max_generate_items
                )
                
                if not success:
                    self.log(f"âŒ ç”Ÿæˆè®­ç»ƒæ•°æ®å¤±è´¥: {msg}")
                    return
                
                self.log(f"âœ… {msg}")
            else:
                # æ£€æŸ¥ç°æœ‰è®­ç»ƒæ•°æ®
                with open(training_data_path, 'r', encoding='utf-8') as f:
                    lines = sum(1 for _ in f)
                self.log(f"âœ… ä½¿ç”¨ç°æœ‰è®­ç»ƒæ•°æ®: {training_data_path}")
                self.log(f"ç°æœ‰è®­ç»ƒæ ·æœ¬æ•°: {lines}")
            
            # æ­¥éª¤2: åŠ è½½æ¨¡å‹è¿›è¡Œå¾®è°ƒ
            self.log("=" * 60)
            self.log("ç¬¬äºŒæ­¥: å¼€å§‹æ¨¡å‹å¾®è°ƒ")
            self.log("=" * 60)
            
            self.log("å¼€å§‹å¯¼å…¥è®­ç»ƒåº“...")
            
            # åŠ¨æ€å¯¼å…¥è®­ç»ƒæ‰€éœ€çš„åº“
            import torch
            from transformers import (
                AutoTokenizer,
                AutoModelForCausalLM,
                TrainingArguments,
                Trainer,
                DataCollatorForLanguageModeling
            )
            
            from datasets import Dataset
            import warnings
            warnings.filterwarnings("ignore")
            
            self.log("åº“å¯¼å…¥å®Œæˆ")
            
            # åŠ è½½æ¨¡å‹
            self.log(f"åŠ è½½æ¨¡å‹: {self.config['model_path']}")
            
            # åŠ è½½tokenizer
            tokenizer = AutoTokenizer.from_pretrained(
                self.config['model_path'],
                trust_remote_code=True,
                padding_side="right",
                use_fast=True
            )
            
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
                
            # ç¡®å®šè®¾å¤‡
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.log(f"ä½¿ç”¨è®¾å¤‡: {device}")
            
            # åŠ è½½æ¨¡å‹
            model = AutoModelForCausalLM.from_pretrained(
                self.config['model_path'],
                local_files_only=True,
                device_map="auto",
                trust_remote_code=True,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                low_cpu_mem_usage=True
            )
            
            self.log("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
            
            # åŠ è½½æ•°æ®é›†
            self.log(f"åŠ è½½è®­ç»ƒæ•°æ®é›†: {training_data_path}")
            data = []
            try:
                with open(training_data_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            data.append(json.loads(line))
            except Exception as e:
                self.log(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {str(e)}")
                return
                
            self.log(f"æ•°æ®é›†å¤§å°: {len(data)} ä¸ªæ ·æœ¬")
            
            if len(data) == 0:
                self.log("âŒ æ•°æ®é›†ä¸ºç©º")
                return
                
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            self.log("å‡†å¤‡è®­ç»ƒæ•°æ®...")
            processed_data = []
            for item in data[:100]:  # é™åˆ¶æ ·æœ¬æ•°é‡ï¼Œé¿å…å†…å­˜ä¸è¶³
                instruction = item.get("instruction", "")
                code = item.get("code", "")
                
                # åˆ›å»ºæ¨¡å‹è¾“å…¥æ ¼å¼
                messages = [
                    {"role": "system", "content": "You are a helpful AI assistant that writes Python code."},
                    {"role": "user", "content": instruction},
                    {"role": "assistant", "content": code}
                ]
                
                # ä½¿ç”¨Qwenç‰¹å®šçš„æ ¼å¼
                text = f"<|im_start|>system\n{messages[0]['content']}<|im_end|>\n"
                text += f"<|im_start|>user\n{messages[1]['content']}<|im_end|>\n"
                text += f"<|im_start|>assistant\n{messages[2]['content']}<|im_end|>\n"
                
                processed_data.append({"text": text})
            
            # åˆ›å»ºæ•°æ®é›†
            dataset = Dataset.from_list(processed_data)
            
            # åˆ†å‰²è®­ç»ƒ/éªŒè¯é›†
            if len(dataset) > 20:
                split_dataset = dataset.train_test_split(test_size=0.1, seed=42)
                train_dataset = split_dataset["train"]
                eval_dataset = split_dataset["test"]
            else:
                train_dataset = dataset
                eval_dataset = dataset.select(range(min(5, len(dataset))))
                
            self.log(f"è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(eval_dataset)}")
            
            # æ•°æ®é¢„å¤„ç†
            def preprocess_function(examples):
                return tokenizer(
                    examples["text"],
                    truncation=True,
                    max_length=512,  # å‡å°‘é•¿åº¦ä»¥èŠ‚çœå†…å­˜
                    padding="max_length",
                )
                
            self.log("é¢„å¤„ç†æ•°æ®...")
            tokenized_train = train_dataset.map(
                preprocess_function,
                batched=True,
                remove_columns=train_dataset.column_names,
            )
            tokenized_eval = eval_dataset.map(
                preprocess_function,
                batched=True,
                remove_columns=eval_dataset.column_names,
            )
            
            # æ•°æ®æ•´ç†å™¨
            data_collator = DataCollatorForLanguageModeling(
                tokenizer=tokenizer,
                mlm=False,
            )
            
            # è®­ç»ƒå‚æ•°
            training_args = TrainingArguments(
                output_dir=self.config['output_dir'],
                num_train_epochs=self.config['num_epochs'],
                per_device_train_batch_size=self.config['batch_size'],
                per_device_eval_batch_size=self.config['batch_size'],
                gradient_accumulation_steps=2,
                warmup_steps=50,
                logging_steps=5,
                save_strategy="epoch",
                eval_strategy="epoch",
                learning_rate=self.config['learning_rate'],
                weight_decay=0.01,
                fp16=False,
                push_to_hub=False,
                report_to="none",
                gradient_checkpointing=True,
            )
            
            # åˆ›å»ºTrainer
            trainer = Trainer(
                model=model,
                args=training_args,
                train_dataset=tokenized_train,
                eval_dataset=tokenized_eval,
                tokenizer=tokenizer,
                data_collator=data_collator,
            )
            
            # å¼€å§‹è®­ç»ƒ
            self.log("å¼€å§‹è®­ç»ƒ...")
            trainer.train()
            
            # ä¿å­˜æ¨¡å‹
            self.log("ä¿å­˜æ¨¡å‹...")
            trainer.save_model()
            tokenizer.save_pretrained(self.config['output_dir'])
            
            self.log("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
            self.log(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {self.config['output_dir']}")
            
        except ImportError as e:
            self.log(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {str(e)}")
            self.log("è¯·è¿è¡Œ: pip install torch transformers datasets")
        except Exception as e:
            self.log(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            self.log(traceback.format_exc())

def start_training_interface(config_data):
    """å¼€å§‹è®­ç»ƒç•Œé¢å‡½æ•°"""
    global is_training, training_thread
    is_training = False
    training_thread = None
    
    if is_training:
        return "âš ï¸ è®­ç»ƒå·²ç»åœ¨è¿›è¡Œä¸­...", False
    
    # æ›´æ–°é…ç½®
    config = DEFAULT_CONFIG.copy()
    config.update(config_data)
    
    # æ£€æŸ¥å¿…è¦å‚æ•°
    required_fields = ["model_path", "mbpp_dataset_path", "output_dir"]
    for field in required_fields:
        if not config.get(field):
            return f"âŒ è¯·å¡«å†™{field}", False
    
    # æ£€æŸ¥MBPPæ•°æ®é›†
    mbpp_path = config.get("mbpp_dataset_path", DEFAULT_CONFIG["mbpp_dataset_path"])
    if not os.path.exists(mbpp_path):
        return f"âŒ MBPPæ•°æ®é›†ä¸å­˜åœ¨: {mbpp_path}", False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config["output_dir"], exist_ok=True)
    
    # å¼€å§‹è®­ç»ƒçº¿ç¨‹
    training_thread = TrainingThread(config, log)
    is_training = True
    training_thread.start()
    
    start_msg = f"""
ğŸš€ å¼€å§‹æ¨¡å‹å¾®è°ƒä»»åŠ¡...

ç¬¬ä¸€é˜¶æ®µ: ç”Ÿæˆè®­ç»ƒæ•°æ®
- MBPPæ•°æ®é›†: {config.get('mbpp_dataset_path', DEFAULT_CONFIG["mbpp_dataset_path"])}
- æœ€å¤§ç”Ÿæˆæ•°é‡: {config.get('max_generate_items', DEFAULT_CONFIG["max_generate_items"])}
- è¾“å‡ºè·¯å¾„: {config.get('training_dataset_path', DEFAULT_CONFIG["training_dataset_path"])}

ç¬¬äºŒé˜¶æ®µ: æ¨¡å‹å¾®è°ƒ
- æ¨¡å‹: {config['model_path']}
- è¾“å‡ºç›®å½•: {config['output_dir']}
- è®­ç»ƒè½®æ•°: {config['num_epochs']}
- å­¦ä¹ ç‡: {config['learning_rate']}
- æ‰¹å¤§å°: {config['batch_size']}

è®­ç»ƒæ—¥å¿—å°†åœ¨ä¸‹æ–¹æ˜¾ç¤º...
    """
    
    log(start_msg)
    return "âœ… è®­ç»ƒå·²å¼€å§‹", True

is_training = False
training_thread = None
